{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import os\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "#various utilities that dont have another home\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from numpy import expand_dims\n",
    "#expand the shape of an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from keras import backend as k\n",
    "from keras.layers import Input , Lambda , Conv2D , BatchNormalization,LeakyReLU, ZeroPadding2D , UpSampling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model , Model\n",
    "from keras.layers import add, concatenate\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self,weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major, = struct.unpack('i', w_f.read(4))\n",
    "            minor, = struct.unpack('i', w_f.read(4))\n",
    "            revision, =struct.unpack('i',w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor)>=2 and major <1000 and minor <1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major >1000 ) or (minor > 1000)\n",
    "\n",
    "            binary = w_f.read()\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary , dtype= 'float32')\n",
    "\n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size : self.offset]\n",
    "    \n",
    "    def load_weights(self, model):\n",
    "        for i in range(106):\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_'+str(i))\n",
    "                print(\"loading weights of convolution #\"+str(i))\n",
    "\n",
    "                if i not in [81,93,105]:\n",
    "                    norm_layer = model.get_layer('bnorm_'+ str(i))\n",
    "\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "                    beta = self.read_bytes(size) #bias\n",
    "                    gamma  = self.read_bytes(size)# scale\n",
    "                    mean = self.read_bytes(size) #mean\n",
    "                    var= self.read_bytes(size) #variance\n",
    "\n",
    "                    weights = norm_layer.set_weights([gamma, beta , mean , var])\n",
    "                \n",
    "                if len(conv_layer.get_weights())>1:\n",
    "                    bias = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.weights()[0].shape))\n",
    "\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel , bias])\n",
    "                \n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = self.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\"+str(i) )\n",
    "    def reset(self):\n",
    "        self.offset = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inp , convs , skip = True):\n",
    "    x= inp\n",
    "    count=0\n",
    "\n",
    "    for conv in convs:\n",
    "        if count == (len(convs)-2) and skip:\n",
    "            skip_connection = x\n",
    "        count+=1\n",
    "\n",
    "        if conv['stride']>1 : x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
    "        #peculiar padding added to darknet as it prefer left and top\n",
    "        x = Conv2D(conv['filter'],\n",
    "                   conv['kernel'],\n",
    "                   stride = conv['stride'],\n",
    "                   padding = 'valid ' if conv['stride']>1 else'same',\n",
    "                   name = 'conv_' + str(conv['layer_idx']),\n",
    "                   use_bias= False if conv['bnorm'] else True)(x)\n",
    "        \n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon= 0.001, name = 'bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']:x = LeakyReLU(alpha = 0.1 , name = 'leaky_'+ str(conv['layer_idx']))(x)\n",
    "    return add([skip_connection, x]) if skip else x\n",
    "#peculiar padding as darknet prefer left and top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creatinng the yolo model\n",
    "def make_yolov3_model():\n",
    "    input_image = Input(shape = (None , None ,3))\n",
    "\n",
    "    #Layer 0 =>4\n",
    "    x = _conv_block(input_image,[{'filter': 32 , 'kernel': 3 , 'stride': 1, 'bnorm' :True , 'leaky': True , 'layer_idx':0},\n",
    "                                  {'filter': 64 , 'kernel': 3 , 'stride' :2 , 'bnorm':True , 'leaky':True , 'layer_idx':1},\n",
    "                                  {'filter': 32 , 'kernel':1 , 'stride' :1, 'bnorm':True , 'leaky':True , 'layer_idx':2},\n",
    "                                  {'filter': 64 , 'kernel':3 , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':3}])\n",
    "    #layer 5=>8\n",
    "    x = _conv_block(x , [{'filter':128 , 'kernel':3  , 'stride':2 , 'bnorm':True , 'leaky': True , 'layer_idx':5},\n",
    "                         {'filter': 64, 'kernel':1 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':6},\n",
    "                         {'filter':128 , 'kernel':3 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':7 }])\n",
    "    \n",
    "    #layer 9=>11\n",
    "    x = _conv_block(x, [{'filter': 64 , 'kernel':1 , 'stride':1 , 'bnorm':True ,'leaky':True , 'layer_idx':9},\n",
    "                        {'filter': 128 , 'kernel':3 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':10}])\n",
    "    \n",
    "    # layer 12 =>15\n",
    "    x = _conv_block(x ,[{'filter':256 , 'kernel':3  , 'stride':2 , 'bnorm':True , 'leaky': True , 'layer_idx':12},\n",
    "                         {'filter': 128, 'kernel':1 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':13},\n",
    "                         {'filter':256 , 'kernel':3 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':14}])\n",
    "    \n",
    "    #layer 16 =>46\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x , [{'filter':128 , 'kernel':1  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':16 + i*3},\n",
    "                         {'filter': 256, 'kernel':3 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':17 + i*3}])\n",
    "        \n",
    "    skip_36 = x\n",
    "\n",
    "    #layer 37=>40\n",
    "    x = _conv_block(x, [{'filter':512 , 'kernel':3  , 'stride':2 , 'bnorm':True , 'leaky': True , 'layer_idx':37},\n",
    "                         {'filter': 256, 'kernel':1 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':38},\n",
    "                         {'filter':512 , 'kernel':3 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':39}])\n",
    "    \n",
    "    # layer 41 => 61\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x , [{'filter':256 , 'kernel':1  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':41 + i*3},\n",
    "                         {'filter': 512, 'kernel':3 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx': 42 + i*3}])\n",
    "        \n",
    "    skip_61 = x \n",
    "    \n",
    "    #layer 62 => 65\n",
    "    x = _conv_block(x,[{'filter':1024 , 'kernel':3  , 'stride':2 , 'bnorm':True , 'leaky': True , 'layer_idx':62},\n",
    "                       {'filter': 512, 'kernel':1 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx': 63},\n",
    "                       {'filter':1024 , 'kernel':3 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':64 }])\n",
    "    \n",
    "    #layer 66 =>74\n",
    "\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x , [{'filter':512 , 'kernel':1  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx': 66+i*3},\n",
    "                         {'filter': 1024, 'kernel':3 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx': 67+ i*3}])\n",
    "        \n",
    "    #layer 75 =>79\n",
    "    x = _conv_block(x ,[{'filter':512 , 'kernel':1 , 'stride':1, 'bnorm':True , 'leaky': True , 'layer_idx':75},\n",
    "                         {'filter': 1024, 'kernel':3 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':76},\n",
    "                         {'filter':512 , 'kernel':1 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':77},\n",
    "                         {'filter':1024 , 'kernel':3  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':78},\n",
    "                         {'filter': 512, 'kernel':1 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':79}] , skip = False)\n",
    "    \n",
    "    #layer 80 =>82\n",
    "    yolo_82 = _conv_block(x , [{'filter':1024 , 'kernel':3  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':80},\n",
    "                               {'filter': 225, 'kernel':1 , 'stride':1, 'bnorm': False , 'leaky':False, 'layer_idx':81}])\n",
    "    \n",
    "    #layer 83 =>86\n",
    "    x = _conv_block( x , [{'filter': 1024 , 'kernel': 3, 'stride' : 1, 'bnorm': True , 'leaky': True, 'layer_idx': 84}], skip = False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x= concatenate([x, skip_61])\n",
    "\n",
    "    #layer 87 = >91\n",
    "    x = _conv_block(x , [{'filter':256 , 'kernel':1  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':87},\n",
    "                         {'filter': 512, 'kernel':3 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':88},\n",
    "                         {'filter':256 , 'kernel':1 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':89},\n",
    "                         {'filter':512 , 'kernel':3  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':90},\n",
    "                         {'filter': 256, 'kernel':1 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':91}], skip= False)\n",
    "    \n",
    "    #layer 92=>94\n",
    "    yolo_94 = _conv_block(x ,[{'filter':512 , 'kernel':3  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx':92},\n",
    "                              {'filter': 255, 'kernel':1 , 'stride':1, 'bnorm': False , 'leaky':False, 'layer_idx':93}], skip = False)\n",
    "    \n",
    "    #layer 95=>98\n",
    "    x = _conv_block( x, [{'filter':128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx':96}], skip = False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    #layer 99 =>106\n",
    "    yolo_106 = _conv_block(x , [{'filter':128 , 'kernel':1  , 'stride':1, 'bnorm':True , 'leaky': True , 'layer_idx':99},\n",
    "                                {'filter':256 , 'kernel':3 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':100},\n",
    "                                {'filter':128 , 'kernel':1 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':101 },\n",
    "                                {'filter':256 , 'kernel':3  , 'stride':1 , 'bnorm':True , 'leaky': True , 'layer_idx': 102},\n",
    "                                {'filter':128, 'kernel':1 , 'stride':1, 'bnorm': True , 'leaky':True, 'layer_idx':103},\n",
    "                                {'filter':256 , 'kernel':3 , 'stride':1 , 'bnorm':True, 'leaky':True , 'layer_idx':104 },\n",
    "                                {'filter':255 , 'kernel':1 , 'stride':1 , 'bnorm':False, 'leaky':False , 'layer_idx':105 }])\n",
    "    model = Model(input_image , [yolo_82 , yolo_94 , yolo_106])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
